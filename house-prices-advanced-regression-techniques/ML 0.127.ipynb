{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae1fc03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the training and test datasets\n",
    "train_data_path = 'train.csv'\n",
    "test_data_path = 'test.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e192a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Custom Transformer for Feature Engineering\n",
    "class FeatureEngineering(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X['TotalSF'] = X['TotalBsmtSF'] + X['1stFlrSF'] + X['2ndFlrSF']\n",
    "        X['Age'] = X['YrSold'] - X['YearBuilt']\n",
    "        X['YearsSinceRemodel'] = X['YrSold'] - X['YearRemodAdd']\n",
    "        X['AreaRatio'] = X['GrLivArea'] / X['LotArea']\n",
    "        X['LotFrontage'] = X.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "        X['MSZoning'] = X['MSZoning'].fillna(X['MSZoning'].mode()[0])\n",
    "\n",
    "        X['Remodeled'] = (X['YearBuilt'] != X['YearRemodAdd']).astype(int)\n",
    "        X['BsmtFinRatio'] = X['BsmtFinSF1'] / X['TotalBsmtSF'].replace(0, 1)\n",
    "        X['GarageLotRatio'] = X['GarageArea'] / X['LotArea']\n",
    "        X['HasMasVnr'] = (X['MasVnrArea'] > 0).astype(int)\n",
    "        X['HasGarage'] = (X['GarageArea'] > 0).astype(int)\n",
    "        X['HasBsmt'] = (X['TotalBsmtSF'] > 0).astype(int)\n",
    "        X['LogLotArea'] = np.log(X['LotArea'] + 1)\n",
    "        \n",
    "                # Interaction features\n",
    "        X['QualSF'] = X['OverallQual'] * X['TotalSF']\n",
    "        \n",
    "        return X\n",
    "    \n",
    "# The ordinal encoding for ordinal columns\n",
    "ordinal_encoding = {\n",
    "    'ExterQual': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'ExterCond': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'BsmtQual': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'BsmtCond': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'HeatingQC': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'KitchenQual': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'FireplaceQu': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'GarageQual': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'GarageCond': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'PoolQC': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
    "    # Add other ordinal columns with their respective order if needed\n",
    "}\n",
    "# Define columns\n",
    "numerical_cols = train_data.select_dtypes(include=['int64', 'float64']).columns.drop('SalePrice')\n",
    "categorical_cols = train_data.select_dtypes(include=['object']).columns\n",
    "ordinal_cols = ['ExterQual', \n",
    "                'ExterCond', \n",
    "                'BsmtQual', \n",
    "                'BsmtCond', \n",
    "                'HeatingQC', \n",
    "                'KitchenQual', \n",
    "                'FireplaceQu', \n",
    "                'GarageQual', \n",
    "                'GarageCond', \n",
    "                'PoolQC'\n",
    "               ]\n",
    "\n",
    "# Pipeline for numerical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer()), # Using IterativeImputer\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "# Pipeline for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Pipeline for ordinal features\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder(categories=[ordinal_encoding[col] for col in ordinal_cols]))\n",
    "])\n",
    "\n",
    "# Combining transformers into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, numerical_cols),\n",
    "    ('cat', categorical_transformer, categorical_cols),\n",
    "    ('ord', ordinal_transformer, ordinal_cols)\n",
    "])\n",
    "\n",
    "# Adjust the feature selection step\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('feature_eng', FeatureEngineering()),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(f_regression, k='all'))\n",
    "])\n",
    "\n",
    "# Separate the target variable in training data\n",
    "y_train = train_data['SalePrice']\n",
    "X_train = train_data.drop('SalePrice', axis=1)\n",
    "\n",
    "# Apply the full pipeline to the training and test data\n",
    "X_train_processed = full_pipeline.fit_transform(X_train, y_train)\n",
    "X_test_processed = full_pipeline.transform(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "281c7483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE Log Score: 0.15172760646172523\n",
      "Gradient Boosting RMSE Log Score: 0.1369481443849903\n",
      "CatBoost RMSE Log Score: 0.12593825277924778\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Custom RMSE log scorer function\n",
    "def rmse_log(y_true, y_pred):\n",
    "    y_true = np.where(y_true <= 0, np.finfo(float).eps, y_true)\n",
    "    y_pred = np.where(y_pred <= 0, np.finfo(float).eps, y_pred)\n",
    "    return np.sqrt(mean_squared_error(np.log(y_true), np.log(y_pred)))\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = X_train_processed\n",
    "y = y_train\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize and train the models\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "gb_model = GradientBoostingRegressor(\n",
    "                                    n_estimators=3000, \n",
    "                                    learning_rate=0.05, \n",
    "                                    max_depth=4,\n",
    "                                    max_features='sqrt',\n",
    "                                    min_samples_leaf=15,\n",
    "                                    min_samples_split=10,\n",
    "                                    loss='huber',\n",
    "                                    random_state=42)\n",
    "cb_model = CatBoostRegressor(\n",
    "                                    iterations=3000,\n",
    "                                    learning_rate=0.05,\n",
    "                                    depth=4,\n",
    "                                    loss_function='RMSE',\n",
    "                                    random_state=42,\n",
    "                                    l2_leaf_reg=3,\n",
    "                                    border_count=128,\n",
    "                                    bagging_temperature=1,\n",
    "                                    early_stopping_rounds=50,\n",
    "                                    boosting_type='Ordered',\n",
    "                                    verbose=False\n",
    ")\n",
    "\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "gb_model.fit(X_train, y_train)\n",
    "cb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "gb_pred = gb_model.predict(X_test)\n",
    "cb_pred = cb_model.predict(X_test)\n",
    "\n",
    "rf_rmse_log_score = rmse_log(y_test, rf_pred)\n",
    "gb_rmse_log_score = rmse_log(y_test, gb_pred)\n",
    "cb_rmse_log_score = rmse_log(y_test, cb_pred)\n",
    "\n",
    "# Print the RMSE log scores\n",
    "print(\"Random Forest RMSE Log Score:\", rf_rmse_log_score)\n",
    "print(\"Gradient Boosting RMSE Log Score:\", gb_rmse_log_score)\n",
    "print(\"CatBoost RMSE Log Score:\", cb_rmse_log_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "953ddc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'house_price_predictions.csv'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming test_data contains an 'Id' column for identification\n",
    "test_ids = test_data['Id']\n",
    "\n",
    "# Predict house prices using the trained models\n",
    "rf_test_pred = rf_model.predict(X_test_processed)\n",
    "gb_test_pred = gb_model.predict(X_test_processed)\n",
    "cb_test_pred = cb_model.predict(X_test_processed)\n",
    "\n",
    "# Average predictions from both models (or you can choose one)\n",
    "average_pred = (cb_test_pred)\n",
    "# Create a DataFrame for submission\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'SalePrice': average_pred\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission.to_csv('house_price_predictions.csv', index=False)\n",
    "\n",
    "# Provide the path for downloading the file\n",
    "csv_file_path = 'house_price_predictions.csv'\n",
    "csv_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bc37c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a96a9cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d11c26c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a8dd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd78fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
